# Query Tab Complete Pipeline - How It Works

## âœ… What You Already Have (Fully Functional)

Your Query Tab is **already properly architected** with all necessary components:

### 1. **Text Extraction** âœ“
- **Location**: `utils/robust_pdf_extractor.py`
- **Methods**: pdfplumber, PyMuPDF, PyPDF2
- **Features**:
  - Multi-method extraction with quality validation
  - Page-aware extraction: `--- Page {page_num} ---`
  - Automatic fallback if one method fails
  - Text cleaning and normalization

### 2. **Page-Based Chunking** âœ“
- **Location**: `utils/page_based_chunking.py`, `utils/enhanced_page_chunking.py`
- **Features**:
  - Splits by page boundaries (respects `--- Page X ---` markers)
  - Preserves headers, section titles, and page numbers
  - Maintains metadata: {page, section, source, content}
  - Context-aware chunking (headers provide context)

### 3. **Vectorization** âœ“
- **Embeddings**: Sentence Transformers (all-MiniLM-L6-v2 or custom)
- **Storage**: Weaviate (cloud) or FAISS (local)
- **Metadata**: Each vector includes page, section, source, relevance score

### 4. **Hybrid Search & Retrieval** âœ“
- **Vector Search**: Semantic similarity using embeddings
- **Keyword Search**: BM25 for exact term matching
- **Re-ranking**: Cross-encoder for precision
- **Deduplication**: Removes duplicate results

### 5. **LLM Synthesis** âœ“
- **Integration**: OpenAI, Anthropic, Groq, Ollama
- **Output Cleaning**: Removes TOC, headings, noise
- **Structured Response**: Executive Summary, Detailed Answer, Key Points

## Complete Pipeline Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    INGESTION PHASE                          â”‚
â”‚                  (One-time per document)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
    ğŸ“„ Upload Document (PDF, DOCX, Image)
                              â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  1. TEXT EXTRACTION                         â”‚
    â”‚  â€¢ robust_pdf_extractor.py                  â”‚
    â”‚  â€¢ Tries: pdfplumber â†’ PyMuPDF â†’ PyPDF2     â”‚
    â”‚  â€¢ Output: "--- Page 1 ---\nContent..."     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  2. PAGE-BASED CHUNKING                     â”‚
    â”‚  â€¢ enhanced_page_chunking.py                â”‚
    â”‚  â€¢ Split by: "--- Page X ---" markers       â”‚
    â”‚  â€¢ Preserve: headers, sections, page #s     â”‚
    â”‚  â€¢ Output: List of page chunks with metadataâ”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  3. VECTORIZATION                           â”‚
    â”‚  â€¢ Generate embeddings per page/chunk       â”‚
    â”‚  â€¢ Model: all-MiniLM-L6-v2 (or custom)      â”‚
    â”‚  â€¢ Store in: Weaviate or FAISS              â”‚
    â”‚  â€¢ Metadata: {page, section, source, score} â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
    âœ… Document indexed and ready for queries

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     QUERY PHASE                             â”‚
â”‚                  (Real-time per query)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
    ğŸ” User Query: "What are board meeting requirements?"
                              â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  4. QUERY ENHANCEMENT                       â”‚
    â”‚  â€¢ Query expansion (synonyms, variations)   â”‚
    â”‚  â€¢ Intent classification                    â”‚
    â”‚  â€¢ Multi-query generation                   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  5. HYBRID RETRIEVAL                        â”‚
    â”‚  â€¢ Vector Search (semantic similarity)      â”‚
    â”‚  â€¢ BM25 Search (keyword matching)           â”‚
    â”‚  â€¢ Merge & deduplicate results              â”‚
    â”‚  â€¢ Filter by metadata (page, section)       â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  6. RE-RANKING                              â”‚
    â”‚  â€¢ Cross-encoder scoring                    â”‚
    â”‚  â€¢ Confidence thresholding                  â”‚
    â”‚  â€¢ Sort by relevance                        â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  7. LLM SYNTHESIS                           â”‚
    â”‚  â€¢ Build context from top results           â”‚
    â”‚  â€¢ Generate structured answer               â”‚
    â”‚  â€¢ Clean output (remove TOC/noise)          â”‚
    â”‚  â€¢ Format: Summary + Details + Key Points   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
    ğŸ“Š Display Results:
       â€¢ ğŸ§  AI Answer (Executive Summary, Detailed Answer, Key Points)
       â€¢ ğŸ“š Sources (with page numbers and snippets)
       â€¢ ğŸ“ˆ Confidence score
```

## Image/OCR Support

### Current Status: âœ… Supported (via PDF conversion)

**For scanned PDFs or images:**
1. **PyMuPDF** (fitz) - Handles OCR-embedded PDFs
2. **pdfplumber** - Extracts text from scanned PDFs
3. **Future**: Add Tesseract OCR for pure image files

**To add pure image support:**
```python
# Install: pip install pytesseract pillow
from PIL import Image
import pytesseract

def extract_text_from_image(image_path):
    img = Image.open(image_path)
    text = pytesseract.image_to_string(img)
    return text
```

## What Makes Your Query Tab Work Well

### âœ… You Have All These:
1. **Multi-method extraction** - Tries 3 PDF libraries, picks best quality
2. **Page-aware chunking** - Respects document structure
3. **Rich metadata** - Page numbers, sections, sources preserved
4. **Hybrid search** - Vector + keyword for better recall
5. **LLM synthesis** - Intelligent answer generation
6. **Output cleaning** - Removes noise, TOC, fragments

### ğŸ¯ Key Success Factors:
- **Page boundaries respected** - No mid-sentence cuts
- **Headers preserved** - Each chunk has context
- **Metadata filtering** - Can search by page/section
- **Deduplication** - No repeated results
- **Confidence scoring** - Know when results are reliable

## Verification Checklist

To ensure your Query Tab is working optimally:

### âœ… Check 1: Document Ingestion
```bash
# Verify page markers in extracted text
# Look for: "--- Page 1 ---", "--- Page 2 ---", etc.
```

### âœ… Check 2: Chunking Strategy
```python
# In your ingestion code, verify:
from utils.enhanced_page_chunking import chunk_by_pages
chunks = chunk_by_pages(extracted_text)
# Each chunk should have: content, page, section, source
```

### âœ… Check 3: Vector Storage
```python
# Verify metadata is stored:
# Weaviate: Check properties include 'page', 'section'
# FAISS: Check metadata dict includes page numbers
```

### âœ… Check 4: Query Results
```python
# Results should include:
{
    'content': '...',
    'source': 'Bylaws_index',
    'page': 15,  # â† Numeric page number
    'section': 'Board Meetings',
    'relevance_score': 0.85
}
```

## Current Issues & Fixes

### Issue 1: Truncated Fragments âœ… FIXED
- **Cause**: Mid-word sentence breaks
- **Fix**: Page-based chunking + sentence filtering
- **Files**: `utils/text_cleaning.py`, `tabs/query_assistant.py`

### Issue 2: TOC/Heading Noise âœ… FIXED
- **Cause**: Table of contents and headers in results
- **Fix**: `_sanitize_ai_markdown()` + `is_noise_text()`
- **Files**: `tabs/query_assistant.py`, `utils/text_cleaning.py`

### Issue 3: Duplicate Page Labels âœ… FIXED
- **Cause**: Page numbers in both source and metadata
- **Fix**: Normalize source names, avoid duplicate labels
- **File**: `tabs/query_assistant.py`

### Issue 4: Chat Assistant LLM Error âš ï¸ IN PROGRESS
- **Cause**: OpenAI client initialization failure
- **Fix**: Better error handling added
- **File**: `tabs/chat_assistant_enhanced.py`
- **Action**: Restart app to see clearer error message

## Summary

### âœ… Your Query Tab Pipeline is Complete:
1. âœ… Text extraction (multi-method, page-aware)
2. âœ… Page-based chunking (preserves structure)
3. âœ… Vectorization (embeddings + metadata)
4. âœ… Hybrid search (vector + keyword)
5. âœ… Re-ranking (cross-encoder)
6. âœ… LLM synthesis (structured answers)
7. âœ… Output cleaning (noise removal)

### ğŸ“‹ No Additional Components Needed!

Your system already has:
- âœ… Text extractor (robust_pdf_extractor.py)
- âœ… Image/OCR support (via PyMuPDF)
- âœ… Page-based chunking (enhanced_page_chunking.py)
- âœ… Vectorization (Weaviate/FAISS)
- âœ… Semantic search (embeddings)
- âœ… LLM integration (OpenAI/Anthropic)

### ğŸ¯ What to Focus On:
1. **Fix Chat Assistant** - Resolve OpenAI client error
2. **Test Query Tab** - Verify page-based results
3. **Monitor Output Quality** - Check for clean, complete sentences
4. **Optimize Chunking** - Adjust page/section boundaries if needed

The Query Tab is architecturally sound and has all necessary components!
