"""
MCP Dashboard Tab
================
Model Context Protocol monitoring and system management.
Access Level: Admin Only
"""

import json
import logging
import os
import sys
import time
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List

import pandas as pd
import streamlit as st

# Add the project root to the path for imports
project_root = Path(__file__).resolve().parent.parent
sys.path.insert(0, str(project_root))

from mcp.logger import mcp_logger
from utils.simple_vector_manager import get_simple_vector_status
from utils.weaviate_ingestion_helper import get_weaviate_ingestion_helper

SETTINGS_PATH = project_root / "config" / "mcp_settings.json"


def load_mcp_settings() -> Dict[str, Any]:
    """Load MCP dashboard settings from disk with defaults."""
    defaults: Dict[str, Any] = {
        "log_level": "INFO",
        "retention_days": 30,
        "enable_alerts": True,
        "auto_refresh": False,
        "auto_refresh_interval": 60,
        "cost_per_1k_prompt": 0.0,
        "cost_per_1k_completion": 0.0,
    }

    if SETTINGS_PATH.exists():
        try:
            with SETTINGS_PATH.open("r", encoding="utf-8") as handle:
                persisted = json.load(handle)
            for key, value in persisted.items():
                if key in defaults:
                    defaults[key] = value
        except Exception as exc:  # pragma: no cover - defensive logging
            logging.getLogger(__name__).warning(
                "Failed to load MCP settings from %s: %s", SETTINGS_PATH, exc
            )
    return defaults


def save_mcp_settings(settings: Dict[str, Any]) -> None:
    """Persist MCP dashboard settings to disk."""
    try:
        SETTINGS_PATH.parent.mkdir(parents=True, exist_ok=True)
        with SETTINGS_PATH.open("w", encoding="utf-8") as handle:
            json.dump(settings, handle, indent=2)
    except Exception as exc:  # pragma: no cover - defensive logging
        logging.getLogger(__name__).error(
            "Failed to save MCP settings to %s: %s", SETTINGS_PATH, exc
        )


def collect_service_health() -> List[Dict[str, str]]:
    """Gather health information for key platform dependencies."""
    services: List[Dict[str, str]] = []

    # Weaviate (cloud vector DB)
    try:
        helper = get_weaviate_ingestion_helper()
        start = time.time()
        reachable = helper.test_connection()
        latency_ms = max(1, int((time.time() - start) * 1000))
        status_icon = "🟢" if reachable else "🟠"
        status_label = "Healthy" if reachable else "Degraded"
        services.append(
            {
                "Service": "Weaviate",
                "Status": f"{status_icon} {status_label}",
                "Details": f"Latency: {latency_ms} ms" if reachable else "Reachable but reported issues",
            }
        )
    except Exception as exc:  # pragma: no cover - diagnostic only
        services.append(
            {
                "Service": "Weaviate",
                "Status": "🔴 Error",
                "Details": str(exc),
            }
        )

    # Local FAISS indexes
    try:
        faiss_status, faiss_detail = get_simple_vector_status()
        status_icon = "🟢" if faiss_status == "Ready" else "🟡"
        services.append(
            {
                "Service": "FAISS Indexes",
                "Status": f"{status_icon} {faiss_status}",
                "Details": faiss_detail,
            }
        )
    except Exception as exc:  # pragma: no cover - diagnostic only
        services.append(
            {
                "Service": "FAISS Indexes",
                "Status": "🔴 Error",
                "Details": str(exc),
            }
        )

    # OpenAI configuration check (no live call to avoid billing)
    if os.getenv("OPENAI_API_KEY"):
        services.append(
            {
                "Service": "OpenAI API",
                "Status": "🟢 Configured",
                "Details": "API key present in environment",
            }
        )
    else:
        services.append(
            {
                "Service": "OpenAI API",
                "Status": "🟡 Missing Key",
                "Details": "Set OPENAI_API_KEY for LLM features",
            }
        )

    return services


def render_mcp_dashboard(user, permissions, auth_middleware):
    """Enterprise-grade MCP dashboard implementation with comprehensive metrics."""
    logger = logging.getLogger(__name__)

    if not permissions.get("can_view_mcp", False):
        st.error("❌ MCP Dashboard requires Admin privileges")
        return

    auth_middleware.log_user_action("ACCESS_MCP_TAB")

    if hasattr(user, "username") and hasattr(user, "role"):
        username = user.username
        role = user.role.value
    else:
        username = user.get("username", "Unknown")
        role = user.get("role", "unknown")

    mcp_logger.log_operation(
        operation="ACCESS_MCP_DASHBOARD",
        username=username,
        user_role=role,
        status="success",
        severity="info",
    )

    settings = load_mcp_settings()

    st.header("🔄 Model Context Protocol Dashboard")
    st.info(f"👤 Logged in as: **{username}** ({role.title() if isinstance(role, str) else role})")

    if settings.get("auto_refresh"):
        interval = int(settings.get("auto_refresh_interval", 60))
        st.experimental_autorefresh(interval=interval * 1000, key="mcp_auto_refresh")

    with st.expander("ℹ️ What is Model Context Protocol (MCP)?", expanded=False):
        st.markdown(
            """
            **Model Context Protocol (MCP)** is a framework for managing and monitoring AI model interactions:

            - 🔍 **Context Tracking**: Monitor how AI models use and process information
            - 📊 **Operation Logging**: Track all AI operations and their outcomes
            - 🔧 **Tool Management**: Manage AI tools and their usage patterns
            - 💾 **Data Flow**: Monitor data flow between different AI components
            - 🔒 **Security Monitoring**: Track access patterns and security events
            """
        )

    metrics = mcp_logger.get_dashboard_metrics()
    latency_stats = mcp_logger.get_latency_stats(hours=24)
    status_breakdown = mcp_logger.get_status_breakdown(hours=24)
    failure_trend = mcp_logger.get_failure_trend(days=7)
    alert_rows = mcp_logger.get_recent_alerts(limit=10)
    token_totals = mcp_logger.get_token_totals(days=7)
    weekly_cost = mcp_logger.get_cost_summary(days=7)

    st.subheader("📊 MCP System Status")
    kpi_col1, kpi_col2, kpi_col3, kpi_col4 = st.columns(4)
    kpi_col1.metric("🔄 Active Sessions", metrics.get("active_sessions", 0))
    kpi_col2.metric("📊 Operations Today", metrics.get("operations_today", 0))
    kpi_col3.metric("🔧 Tools Available", metrics.get("tools_available", 0))
    kpi_col4.metric("⚠️ Alerts (24h)", metrics.get("alerts", 0))

    kpi_col1, kpi_col2, kpi_col3, kpi_col4 = st.columns(4)
    kpi_col1.metric("⏱ Avg Latency (s)", f"{latency_stats['avg']:.2f}" if latency_stats.get("avg") else "--")
    kpi_col2.metric("🚀 P95 Latency (s)", f"{latency_stats['p95']:.2f}" if latency_stats.get("p95") else "--")
    total_ops = sum(status_breakdown.values()) or 1
    failure_rate = status_breakdown.get("failed", 0) / total_ops
    kpi_col3.metric("🔥 Failure Rate", f"{failure_rate:.1%}")
    kpi_col4.metric("💰 Cost (7d)", f"${weekly_cost:,.2f}")

    st.subheader("📈 Hourly System Activity")
    hour_counts = mcp_logger.get_operation_counts_by_hour(days=1)
    hours = list(range(24))
    hourly_df = pd.DataFrame({
        "Hour": [f"{h}:00" for h in hours],
        "Operations": [hour_counts.get(h, 0) for h in hours],
    })
    st.bar_chart(hourly_df.set_index("Hour"))

    st.subheader("⚠️ Recent Alerts & Failures")
    if alert_rows:
        alert_df = pd.DataFrame(
            {
                "Timestamp": [row.get("timestamp") for row in alert_rows],
                "Operation": [row.get("operation") for row in alert_rows],
                "User": [row.get("username") for row in alert_rows],
                "Severity": [row.get("severity") for row in alert_rows],
                "Status": [row.get("status") for row in alert_rows],
                "Error Code": [row.get("error_code", "--") for row in alert_rows],
                "Service": [row.get("service", "--") for row in alert_rows],
            }
        )
        st.dataframe(alert_df, use_container_width=True)
    else:
        st.success("System healthy — no alert-level events in the last 24 hours.")

    st.subheader("🧭 Failure Trend (7 days)")
    if failure_trend:
        failure_df = pd.DataFrame(failure_trend)
        st.line_chart(failure_df.set_index("day"))
    else:
        st.info("No failures recorded in the trailing seven days.")

    st.subheader("📝 Recent MCP Operations")
    operations = mcp_logger.get_recent_operations(limit=50)
    if operations:
        operations_df = pd.DataFrame(
            {
                "Timestamp": [op.get("timestamp") for op in operations],
                "Operation": [op.get("operation") for op in operations],
                "User": [op.get("username") for op in operations],
                "Status": [op.get("status") for op in operations],
                "Service": [op.get("service", "--") for op in operations],
                "Duration (s)": [op.get("duration") for op in operations],
                "Cost": [op.get("cost") for op in operations],
                "Tokens": [op.get("total_tokens") for op in operations],
            }
        )
        st.dataframe(operations_df, use_container_width=True)

        with st.expander("🔍 Inspect Operation Details"):
            labels = [f"{op['operation']} ({op['timestamp']})" for op in operations]
            chosen_label = st.selectbox("Select an operation", labels, key="mcp_op_select")
            if chosen_label:
                chosen_index = labels.index(chosen_label)
                st.json(operations[chosen_index])
    else:
        st.info("No operations logged yet. Use the system to generate telemetry.")

    st.subheader("🤖 LLM Usage & Cost (7 days)")
    if token_totals.get("total", 0) > 0:
        prompt_tokens = token_totals.get("prompt", 0)
        completion_tokens = token_totals.get("response", 0)
        cost_prompt = (prompt_tokens / 1000.0) * settings.get("cost_per_1k_prompt", 0.0)
        cost_completion = (completion_tokens / 1000.0) * settings.get("cost_per_1k_completion", 0.0)
        estimated_cost = cost_prompt + cost_completion
        llm_col1, llm_col2, llm_col3 = st.columns(3)
        llm_col1.metric("Prompt Tokens", f"{prompt_tokens:,}")
        llm_col2.metric("Completion Tokens", f"{completion_tokens:,}")
        llm_col3.metric("Estimated Cost", f"${estimated_cost:,.2f}")
    else:
        st.info("No LLM usage recorded in the last 7 days.")

    st.subheader("🌐 Service Health Snapshot")
    st.dataframe(pd.DataFrame(collect_service_health()), use_container_width=True)

    st.subheader("⚙️ MCP Configuration")
    config_col1, config_col2 = st.columns(2)
    with config_col1:
        new_log_level = st.selectbox(
            "Log Level",
            ["DEBUG", "INFO", "WARNING", "ERROR"],
            index=["DEBUG", "INFO", "WARNING", "ERROR"].index(settings.get("log_level", "INFO")),
            key="mcp_cfg_log_level",
        )
        new_retention = st.number_input(
            "Log Retention (days)",
            min_value=1,
            max_value=365,
            value=int(settings.get("retention_days", 30)),
            key="mcp_cfg_retention",
        )
        new_alerts_enabled = st.checkbox(
            "Enable Real-time Alerts",
            value=bool(settings.get("enable_alerts", True)),
            key="mcp_cfg_alerts",
        )
        new_auto_refresh = st.checkbox(
            "Auto-refresh Dashboard",
            value=bool(settings.get("auto_refresh", False)),
            key="mcp_cfg_auto_refresh",
        )
        new_refresh_interval = st.slider(
            "Refresh Interval (seconds)",
            min_value=15,
            max_value=300,
            value=int(settings.get("auto_refresh_interval", 60)),
            step=15,
            key="mcp_cfg_refresh_interval",
        )
    with config_col2:
        cost_per_prompt = st.number_input(
            "Prompt Cost per 1K tokens ($)",
            min_value=0.0,
            value=float(settings.get("cost_per_1k_prompt", 0.0)),
            step=0.001,
            format="%.3f",
            key="mcp_cfg_cost_prompt",
        )
        cost_per_completion = st.number_input(
            "Completion Cost per 1K tokens ($)",
            min_value=0.0,
            value=float(settings.get("cost_per_1k_completion", 0.0)),
            step=0.001,
            format="%.3f",
            key="mcp_cfg_cost_completion",
        )
        st.caption("Use provider pricing (e.g., OpenAI, Anthropic) to estimate spend.")

    if st.button("💾 Save Configuration", key="mcp_cfg_save"):
        new_settings = {
            "log_level": new_log_level,
            "retention_days": new_retention,
            "enable_alerts": new_alerts_enabled,
            "auto_refresh": new_auto_refresh,
            "auto_refresh_interval": new_refresh_interval,
            "cost_per_1k_prompt": cost_per_prompt,
            "cost_per_1k_completion": cost_per_completion,
        }
        save_mcp_settings(new_settings)
        mcp_logger.log_operation(
            operation="UPDATE_MCP_CONFIG",
            username=username,
            user_role=role,
            status="success",
            severity="info",
            details=new_settings,
        )
        st.success("Configuration saved and persisted.")

    if st.button("♻️ Clear Cached Settings", key="mcp_cfg_clear"):
        if SETTINGS_PATH.exists():
            SETTINGS_PATH.unlink()
        st.cache_data.clear()
        st.cache_resource.clear()
        st.success("Settings cache cleared. Reload to apply defaults.")

    st.subheader("👥 User Activity Report")
    user_activity: Dict[str, int] = {}
    user_operations: Dict[str, Dict[str, int]] = {}
    for op in operations:
        user_name = op.get("username", "unknown")
        user_activity[user_name] = user_activity.get(user_name, 0) + 1
        per_user = user_operations.setdefault(user_name, {})
        op_name = op.get("operation", "unknown")
        per_user[op_name] = per_user.get(op_name, 0) + 1

    if user_activity:
        user_col1, user_col2 = st.columns(2)
        with user_col1:
            user_df = pd.DataFrame({
                "User": list(user_activity.keys()),
                "Operations": list(user_activity.values()),
            })
            st.bar_chart(user_df.set_index("User"))
        with user_col2:
            top_users = sorted(user_activity.items(), key=lambda item: item[1], reverse=True)
            for name, count in top_users[:5]:
                st.markdown(f"**{name}** — {count} operations")
        with st.expander("🔍 Drill into User Operations"):
            selected_user = st.selectbox("Select a user", list(user_operations.keys()), key="mcp_user_select")
            if selected_user:
                detail_df = pd.DataFrame(
                    {
                        "Operation": list(user_operations[selected_user].keys()),
                        "Count": list(user_operations[selected_user].values()),
                    }
                ).sort_values("Count", ascending=False)
                st.dataframe(detail_df, use_container_width=True)
    else:
        st.info("User-level activity will appear once operations are recorded.")

    st.subheader("🔧 MCP Tools Management")
    default_tools = [
        {"name": "document_search", "description": "Search indexed documents", "category": "Search"},
        {"name": "web_scraper", "description": "Scrape web content", "category": "Data Collection"},
        {"name": "pdf_processor", "description": "Extract text from PDF files", "category": "Document Processing"},
        {"name": "chat_engine", "description": "Process chat conversations", "category": "Communication"},
        {"name": "agent_controller", "description": "Manage AI agents", "category": "Agent Management"},
        {"name": "index_manager", "description": "Manage FAISS indexes", "category": "Data Management"},
        {"name": "user_auth", "description": "User authentication services", "category": "Security"},
        {"name": "notification_service", "description": "Send user notifications", "category": "Communication"},
    ]
    for tool in default_tools:
        mcp_logger.register_tool(tool["name"], tool["description"], tool["category"])

    tools = mcp_logger.get_tool_stats()
    if tools:
        tools_df = pd.DataFrame(
            {
                "Tool": [tool.get("name") for tool in tools],
                "Status": [tool.get("status") for tool in tools],
                "Usage": [tool.get("usage_count") for tool in tools],
                "Last Used": [tool.get("last_used_friendly", "Never") for tool in tools],
                "Category": [tool.get("category", "General") for tool in tools],
            }
        )
        st.dataframe(tools_df, use_container_width=True)

        selected_tool = st.selectbox("Manage tool", tools_df["Tool"].tolist(), key="mcp_tool_manage")
        tool_col1, tool_col2 = st.columns(2)
        with tool_col1:
            if st.button("Restart Tool", key="mcp_tool_restart"):
                mcp_logger.log_operation(
                    operation="RESTART_TOOL",
                    username=username,
                    user_role=role,
                    status="success",
                    severity="info",
                    tool_name=selected_tool,
                    details={"action": "restart"},
                )
                st.success(f"Tool {selected_tool} restart request logged.")
        with tool_col2:
            if st.button("Toggle Status", key="mcp_tool_toggle"):
                current_status = next(
                    (tool.get("status", "active") for tool in tools if tool.get("name") == selected_tool),
                    "active",
                )
                new_status = "idle" if current_status == "active" else "active"
                mcp_logger.log_operation(
                    operation="TOGGLE_TOOL_STATUS",
                    username=username,
                    user_role=role,
                    status="success",
                    severity="info",
                    tool_name=selected_tool,
                    details={"old_status": current_status, "new_status": new_status},
                )
                st.success(f"Tool {selected_tool} marked as {new_status}.")
    else:
        st.info("No MCP tools registered yet.")

    st.subheader("🎯 MCP Actions")
    action_col1, action_col2, action_col3, action_col4 = st.columns(4)
    with action_col1:
        if st.button("🔄 Refresh Data", key="mcp_action_refresh"):
            mcp_logger.log_operation(
                operation="REFRESH_MCP_DATA",
                username=username,
                user_role=role,
                status="success",
                severity="info",
            )
            st.experimental_rerun()
    with action_col2:
        if st.button("📊 Export Logs", key="mcp_action_export"):
            export_operations = mcp_logger.get_recent_operations(limit=500)
            if export_operations:
                export_df = pd.DataFrame(export_operations)
                csv_blob = export_df.to_csv(index=False)
                st.download_button(
                    "Download CSV",
                    csv_blob,
                    file_name=f"mcp_logs_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                    mime="text/csv",
                )
            else:
                st.warning("No logs available for export.")
    with action_col3:
        if st.button("🧩 Clear Cache", key="mcp_action_cache"):
            st.cache_data.clear()
            st.cache_resource.clear()
            st.success("Streamlit caches cleared.")
    with action_col4:
        if st.button("🔒 Security Scan", key="mcp_action_security"):
            mcp_logger.log_operation(
                operation="RUN_SECURITY_SCAN",
                username=username,
                user_role=role,
                status="success",
                severity="info",
                details={"scan": "basic"},
            )
            progress = st.progress(0)
            status_box = st.empty()
            for i in range(0, 101, 5):
                progress.progress(i)
                if i == 25:
                    status_box.info("Scanning permissions...")
                elif i == 50:
                    status_box.info("Inspecting API key usage...")
                elif i == 75:
                    status_box.info("Verifying data pipelines...")
                time.sleep(0.05)
            status_box.success("No security issues detected.")


def collect_service_health() -> List[Dict[str, str]]:
    """Gather health information for key platform dependencies."""
    services: List[Dict[str, str]] = []

    # Weaviate (cloud vector DB)
    try:
        helper = get_weaviate_ingestion_helper()
        start = time.time()
        reachable = helper.test_connection()
        latency_ms = int((time.time() - start) * 1000)
        services.append(
            {
                "Service": "Weaviate",
                "Status": "" if reachable else "",
                "Details": f"Latency: {latency_ms} ms" if reachable else "Reachable but reported issues",
            }
        )
    except Exception as exc:  # pragma: no cover - diagnostic only
        services.append(
            {
                "Service": "Weaviate",
                "Status": "",
                "Details": str(exc),
            }
        )

    # Local FAISS indexes
    try:
        faiss_status, faiss_detail = get_simple_vector_status()
        status_icon = "🟢" if faiss_status == "Ready" else "🟡"
        services.append(
            {
                "Service": "FAISS Indexes",
                "Status": f"{status_icon} {faiss_status}",
                "Details": faiss_detail,
            }
        )
    except Exception as exc:  # pragma: no cover - diagnostic only
        services.append(
            {
                "Service": "FAISS Indexes",
                "Status": "🔴 Error",
                "Details": str(exc),
            }
        )

    # OpenAI configuration check (no live call to avoid billing)
    if os.getenv("OPENAI_API_KEY"):
        services.append(
            {
                "Service": "OpenAI API",
                "Status": "🟢 Configured",
                "Details": "API key present in environment",
            }
        )
    else:
        services.append(
            {
                "Service": "OpenAI API",
                "Status": "🟡 Missing Key",
                "Details": "Set OPENAI_API_KEY for LLM features",
            }
        )

    return services

def render_mcp_dashboard(user, permissions, auth_middleware):
    """Enterprise-grade MCP dashboard implementation with comprehensive metrics"""
{{ ... }}
    # Create a logger for this component
    logger = logging.getLogger(__name__)
    
    # Check permissions directly without using a context manager
    if not permissions['can_view_mcp']:
        st.error("❌ MCP Dashboard requires Admin privileges")
        return
        
    # Log the access to the MCP tab
    auth_middleware.log_user_action("ACCESS_MCP_TAB")
    
    # Also log to MCP logger
    if hasattr(user, 'username') and hasattr(user, 'role'):
        username = user.username
        role = user.role.value
    else:
        username = user.get('username', 'Unknown')
        role = user.get('role', 'unknown')
    
    mcp_logger.log_operation(
        operation="ACCESS_MCP_DASHBOARD",
        username=username,
        user_role=role,
        status="success"
    )
    
    st.header("🔄 Model Context Protocol Dashboard")
    st.info(f"👤 Logged in as: **{username}** ({role.title()})")
    
    # What is MCP explanation
    with st.expander("ℹ️ What is Model Context Protocol (MCP)?", expanded=False):
        st.markdown("""
        **Model Context Protocol (MCP)** is a framework for managing and monitoring AI model interactions:
        
        - 🔍 **Context Tracking**: Monitor how AI models use and process information
        - 📊 **Operation Logging**: Track all AI operations and their outcomes
        - 🔧 **Tool Management**: Manage AI tools and their usage patterns
        - 💾 **Data Flow**: Monitor data flow between different AI components
        - 🔒 **Security Monitoring**: Track access patterns and security events
        """)
    
    # Refresh data button
    refresh_data = st.button("🔄 Refresh Dashboard Data", key="refresh_mcp_data")
    
    # MCP Status Overview
    st.subheader("📊 MCP System Status")
    
    # Get real metrics from the database
    metrics = mcp_logger.get_dashboard_metrics()
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("🔄 Active Sessions", f"{metrics['active_sessions']}")
    with col2:
        st.metric("📊 Operations Today", f"{metrics['operations_today']}")
    with col3:
        st.metric("🔧 Tools Available", f"{metrics['tools_available']}")
    with col4:
        st.metric("⚠️ Alerts", f"{metrics['alerts']}")
    
    # Add hourly activity chart
    st.subheader("📈 Hourly System Activity")
    
    # Get hourly operation counts
    hour_counts = mcp_logger.get_operation_counts_by_hour(days=1)
    
    # Create dataframe for the chart
    hours = list(range(24))
    counts = [hour_counts.get(hour, 0) for hour in hours]
    
    # Create a prettier hour labels (1 AM, 2 AM, etc.)
    hour_labels = [f"{h}:00" for h in hours]
    
    hourly_df = pd.DataFrame({
        'Hour': hour_labels,
        'Operations': counts
    })
    
    # Display the chart
    st.bar_chart(hourly_df.set_index('Hour'))
    
    # MCP Operations Log
    st.subheader("📝 Recent MCP Operations")
    
    # Get real operations data from the database
    operations = mcp_logger.get_recent_operations(limit=20)
    
    if operations:
        # Prepare the data for display
        mcp_data = {
            'Timestamp': [],
            'Operation': [],
            'User': [],
            'Status': [],
            'Duration': [],
            'Details': []
        }
        
        for op in operations:
            mcp_data['Timestamp'].append(op.get('timestamp', ''))
            mcp_data['Operation'].append(op.get('operation', ''))
            mcp_data['User'].append(op.get('username', ''))
            
            # Add emoji to status
            status = op.get('status', '')
            if status.lower() == 'success':
                mcp_data['Status'].append('✅ Success')
            elif status.lower() == 'failed':
                mcp_data['Status'].append('❌ Failed')
            else:
                mcp_data['Status'].append(status)
            
            # Format duration
            duration = op.get('duration')
            if duration is not None:
                mcp_data['Duration'].append(f"{duration:.1f}s")
            else:
                mcp_data['Duration'].append('--')
            
            # Extract important details
            details = op.get('details', {})
            detail_text = []
            
            # Get most relevant details
            if isinstance(details, dict):
                if 'model' in details:
                    detail_text.append(f"Model: {details['model']}")
                if 'tokens_used' in details:
                    detail_text.append(f"Tokens: {details['tokens_used']}")
                if 'query' in details:
                    query = details['query']
                    if len(query) > 30:
                        query = query[:27] + "..."
                    detail_text.append(f"Query: {query}")
                if 'trace_id' in details:
                    detail_text.append(f"TraceID: {details['trace_id'][:8]}...")
            
            mcp_data['Details'].append(" | ".join(detail_text) if detail_text else "--")
        
        df = pd.DataFrame(mcp_data)
        st.dataframe(df, use_container_width=True)
        
        # Add operation details expander
        with st.expander("🔍 View Detailed Operation Logs"):
            selected_operation = st.selectbox(
                "Select an operation to view details:",
                [f"{op['operation']} ({op['timestamp']})" for op in operations],
                key="operation_details"
            )
            
            if selected_operation:
                # Find the selected operation
                selected_idx = [f"{op['operation']} ({op['timestamp']})" for op in operations].index(selected_operation)
                operation_details = operations[selected_idx]
                
                st.json(operation_details)
    else:
        st.info("No operations logged yet. Use the system to generate logs.")
    
    # Add LLM Metrics Section
    st.subheader("🤖 LLM Usage Metrics")
    
    # Calculate LLM metrics from operations
    llm_operations = [op for op in operations if op.get('operation', '').startswith(('GENERATE', 'CONTENT_GENERATION'))]
    
    if llm_operations:
        # Extract token usage
        total_tokens = 0
        prompt_tokens = 0
        response_tokens = 0
        model_usage = {}
        
        for op in llm_operations:
            details = op.get('details', {})
            if isinstance(details, dict):
                # Count tokens
                tokens = details.get('tokens_used', 0)
                if tokens:
                    total_tokens += tokens
                
                # Count prompt tokens
                p_tokens = details.get('prompt_tokens', 0)
                if p_tokens:
                    prompt_tokens += p_tokens
                    
                # Count response tokens
                r_tokens = details.get('response_tokens', 0)
                if r_tokens:
                    response_tokens += r_tokens
                    
                # Track model usage
                model = details.get('model', 'unknown')
                if model in model_usage:
                    model_usage[model] += 1
                else:
                    model_usage[model] = 1
        
        # Display token metrics
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("Total Tokens Used", f"{total_tokens:,}")
        with col2:
            st.metric("Prompt Tokens", f"{prompt_tokens:,}")
        with col3:
            st.metric("Response Tokens", f"{response_tokens:,}")
            
        # Display model usage
        st.subheader("Model Usage Distribution")
        model_df = pd.DataFrame({
            'Model': list(model_usage.keys()),
            'Usage Count': list(model_usage.values())
        })
        st.bar_chart(model_df.set_index('Model'))
    else:
        st.info("No LLM operations logged yet. Use the system to generate LLM logs.")
    
    # MCP Configuration
    st.subheader("⚙️ MCP Configuration")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("**🔍 Monitoring Settings:**")
        log_level = st.selectbox(
            "Log Level:",
            ["DEBUG", "INFO", "WARNING", "ERROR"],
            index=1,
            key="mcp_log_level"
        )
        
        retention_days = st.number_input(
            "Log Retention (days):",
            min_value=1, max_value=365, value=30,
            key="mcp_retention"
        )
        
        enable_alerts = st.checkbox(
            "Enable Real-time Alerts",
            value=True,
            key="mcp_alerts"
        )
        
        if st.button("Save Configuration"):
            # Log the configuration update
            mcp_logger.log_operation(
                operation="UPDATE_MCP_CONFIG",
                username=username,
                user_role=role,
                status="success",
                details={
                    "log_level": log_level,
                    "retention_days": retention_days,
                    "enable_alerts": enable_alerts
                }
            )
            st.success("✅ Configuration saved!")
        
        if st.session_state.get('prev_log_level') != log_level:
            # Log the change to the database
            mcp_logger.log_operation(
                operation="UPDATE_LOG_LEVEL",
                username=username,
                user_role=role,
                status="success",
                details={"new_level": log_level}
            )
            st.session_state['prev_log_level'] = log_level
    
    # Add User Activity section
    st.subheader("👥 User Activity Report")
    
    # Get unique users from operations
    user_activity = {}
    user_operations = {}
    
    for op in operations:
        user = op.get('username', 'unknown')
        if user in user_activity:
            user_activity[user] += 1
        else:
            user_activity[user] = 1
            
        # Track operations by user
        operation = op.get('operation', 'unknown')
        if user not in user_operations:
            user_operations[user] = {}
        
        if operation in user_operations[user]:
            user_operations[user][operation] += 1
        else:
            user_operations[user][operation] = 1
    
    # Display user activity
    if user_activity:
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("User Operation Counts")
            user_df = pd.DataFrame({
                'User': list(user_activity.keys()),
                'Operations': list(user_activity.values())
            })
            st.bar_chart(user_df.set_index('User'))
        
        with col2:
            st.subheader("Most Active Users")
            sorted_users = sorted(user_activity.items(), key=lambda x: x[1], reverse=True)
            for user, count in sorted_users[:5]:
                st.markdown(f"**{user}**: {count} operations")
        
        # User details expander
        with st.expander("🔍 User Operation Details"):
            selected_user = st.selectbox(
                "Select a user to view operation details:",
                list(user_operations.keys()),
                key="user_details"
            )
            
            if selected_user and selected_user in user_operations:
                st.markdown(f"### Operations for {selected_user}")
                
                # Create a DataFrame for this user's operations
                op_items = list(user_operations[selected_user].items())
                op_df = pd.DataFrame({
                    'Operation': [op[0] for op in op_items],
                    'Count': [op[1] for op in op_items]
                })
                
                # Sort by count
                op_df = op_df.sort_values('Count', ascending=False)
                
                # Display as a table
                st.dataframe(op_df, use_container_width=True)
    else:
        st.info("No user activity data available yet.")
    
    with col2:
        st.markdown("**📊 Performance Metrics:**")
        
        # Get real operation counts by hour
        hour_counts = mcp_logger.get_operation_counts_by_hour(days=1)
        
        # Prepare data for chart
        chart_data = pd.DataFrame({
            'Hour': list(range(24)),
            'Operations': [hour_counts.get(hour, 0) for hour in range(24)]
        })
        
        st.line_chart(chart_data.set_index('Hour'))
        st.caption("📊 Operations per hour (last 24 hours)")
    
    # MCP Tools Management
    st.subheader("🔧 MCP Tools Management")
    
    # Register default tools if they don't exist in the database
    default_tools = [
        {"name": "document_search", "description": "Search indexed documents", "category": "Search"},
        {"name": "web_scraper", "description": "Scrape web content", "category": "Data Collection"},
        {"name": "pdf_processor", "description": "Extract text from PDF files", "category": "Document Processing"},
        {"name": "chat_engine", "description": "Process chat conversations", "category": "Communication"},
        {"name": "agent_controller", "description": "Manage AI agents", "category": "Agent Management"},
        {"name": "index_manager", "description": "Manage FAISS indexes", "category": "Data Management"},
        {"name": "user_auth", "description": "User authentication services", "category": "Security"},
        {"name": "notification_service", "description": "Send user notifications", "category": "Communication"}
    ]
    
    # Register default tools
    for tool in default_tools:
        mcp_logger.register_tool(
            name=tool["name"],
            description=tool["description"],
            category=tool["category"]
        )
    
    # Get real tool data
    tools = mcp_logger.get_tool_stats()
    
    if tools:
        # Prepare the data for display
        tools_data = {
            'Tool Name': [],
            'Status': [],
            'Usage Count': [],
            'Last Used': [],
            'Category': []
        }
        
        for tool in tools:
            tools_data['Tool Name'].append(tool.get('name', ''))
            
            # Add emoji to status
            status = tool.get('status', '').lower()
            if status == 'active':
                tools_data['Status'].append('🟢 Active')
            elif status == 'idle':
                tools_data['Status'].append('🟡 Idle')
            elif status == 'error':
                tools_data['Status'].append('🔴 Error')
            else:
                tools_data['Status'].append('⚪ Unknown')
            
            tools_data['Usage Count'].append(tool.get('usage_count', 0))
            tools_data['Last Used'].append(tool.get('last_used_friendly', 'Never'))
            tools_data['Category'].append(tool.get('category', 'General'))
        
        # Create a DataFrame and display it
        tools_df = pd.DataFrame(tools_data)
        st.dataframe(tools_df, use_container_width=True)
        
        # Tool management actions
        tool_to_manage = st.selectbox(
            "Select Tool to Manage:",
            options=[t.get('name', '') for t in tools],
            key="tool_selection"
        )
        
        col1, col2 = st.columns(2)
        
        with col1:
            if st.button("Restart Tool", key="restart_tool"):
                mcp_logger.log_operation(
                    operation="RESTART_TOOL",
                    username=username,
                    user_role=role,
                    status="success",
                    tool_name=tool_to_manage,
                    details={"action": "restart"}
                )
                st.success(f"✅ Tool {tool_to_manage} restarted")
        
        with col2:
            if st.button("Toggle Status", key="toggle_status"):
                # Find the current tool status
                current_status = "active"  # default
                for tool in tools:
                    if tool.get('name') == tool_to_manage:
                        current_status = tool.get('status', 'active')
                        break
                
                # Toggle the status
                new_status = "idle" if current_status == "active" else "active"
                
                # Log the action
                mcp_logger.log_operation(
                    operation="TOGGLE_TOOL_STATUS",
                    username=username,
                    user_role=role,
                    status="success",
                    tool_name=tool_to_manage,
                    details={"old_status": current_status, "new_status": new_status}
                )
                
                st.success(f"✅ Tool {tool_to_manage} status changed to {new_status}")
    else:
        st.info("No tools registered yet. Tools will appear here when they are used.")
    
    # MCP Actions
    st.subheader("🎯 MCP Actions")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        if st.button("🔄 Refresh Data", key="mcp_refresh"):
            # Log the refresh action
            mcp_logger.log_operation(
                operation="REFRESH_MCP_DATA",
                username=username,
                user_role=role,
                status="success"
            )
            st.success("✅ MCP data refreshed!")
            # Add a JavaScript snippet to reload the page after a short delay
            st.markdown("""
            <script>
                setTimeout(function() {
                    window.location.reload();
                }, 1000);
            </script>
            """, unsafe_allow_html=True)
    
    with col2:
        if st.button("📊 Export Logs", key="mcp_export"):
            # Log the export action
            mcp_logger.log_operation(
                operation="EXPORT_MCP_LOGS",
                username=username,
                user_role=role,
                status="success"
            )
            
            # Get operations for export
            operations = mcp_logger.get_recent_operations(limit=100)
            
            if operations:
                # Create a DataFrame for download
                export_data = pd.DataFrame(operations)
                
                # Convert to CSV
                csv = export_data.to_csv(index=False)
                
                # Create a download link
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                st.download_button(
                    label="📥 Download CSV",
                    data=csv,
                    file_name=f"mcp_logs_{timestamp}.csv",
                    mime="text/csv",
                    key="download_csv"
                )
                
                st.success("💾 Logs prepared for export!")
            else:
                st.warning("No logs available for export")
    
    with col3:
        if st.button("🧩 Clear Cache", key="mcp_clear_cache"):
            # Log the cache clearing action
            mcp_logger.log_operation(
                operation="CLEAR_MCP_CACHE",
                username=username,
                user_role=role,
                status="success"
            )
            
            # Clear Streamlit cache
            st.cache_data.clear()
            st.cache_resource.clear()
            
            st.success("🧩 MCP cache cleared!")
    
    with col4:
        if st.button("🔒 Security Scan", key="mcp_security"):
            # Log the security scan action
            mcp_logger.log_operation(
                operation="RUN_SECURITY_SCAN",
                username=username,
                user_role=role,
                status="success",
                details={"scan_type": "basic"}
            )
            
            # In a real implementation, you would run actual security checks here
            
            # For demonstration, we'll just simulate a security scan with progress
            progress_bar = st.progress(0)
            scan_status = st.empty()
            
            scan_status.info("Starting security scan...")
            
            for i in range(101):
                # Update progress bar
                progress_bar.progress(i)
                
                if i == 25:
                    scan_status.info("Scanning user permissions...")
                elif i == 50:
                    scan_status.info("Checking for unauthorized access attempts...")
                elif i == 75:
                    scan_status.info("Verifying system integrity...")
                
                time.sleep(0.05)
            
            scan_status.success("🔒 Security scan completed! No issues found.")
